import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder
import warnings
warnings.filterwarnings('ignore')

print("ğŸ§¹ Ø¨Ø¯Ø¡ ØªÙ†Ø¸ÙŠÙ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
df = pd.read_csv('deathrate.csv')
print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {df.shape[0]} ØµÙØŒ {df.shape[1]} Ø¹Ù…ÙˆØ¯")

# Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©)
print("\n1ï¸âƒ£ ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©...")
df.columns = df.columns.str.strip()
print("âœ… ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ù…Ù† Ø§Ù„Ù…Ø³Ø§ÙØ§Øª")

# Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ù†Ø¸ÙØ©
print("\nğŸ“‹ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ:")
for i, col in enumerate(df.columns, 1):
    print(f"{i:2d}. '{col}'")

# Ø§Ù„Ø®Ø·ÙˆØ© 2: ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
target_column = 'Life expectancy'  # Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
print(f"\nğŸ¯ Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù: '{target_column}'")

# Ø§Ù„Ø®Ø·ÙˆØ© 3: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
print("\n2ï¸âƒ£ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©...")

# Ø£ÙˆÙ„Ø§Ù‹: Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
numeric_columns = df.select_dtypes(include=[np.number]).columns
print(f"Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©: {len(numeric_columns)} Ù…ØªØºÙŠØ±")

for col in numeric_columns:
    if df[col].isnull().sum() > 0:
        missing_before = df[col].isnull().sum()
        
        # Ø§Ù…Ù„Ø£ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯ÙˆÙ„Ø© Ø£ÙˆÙ„Ø§Ù‹
        df[col] = df.groupby('Country')[col].transform(
            lambda x: x.fillna(x.mean())
        )
        
        # Ø¥Ø°Ø§ Ù…Ø§ Ø²Ø§Ù„Øª Ù‡Ù†Ø§Ùƒ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù…ØªÙˆØ³Ø· Ø§Ù„Ø­Ø§Ù„Ø© (Status)
        if df[col].isnull().sum() > 0:
            df[col] = df.groupby('Status')[col].transform(
                lambda x: x.fillna(x.mean())
            )
        
        # Ø¥Ø°Ø§ Ù…Ø§ Ø²Ø§Ù„Øª Ù‡Ù†Ø§Ùƒ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¹Ø§Ù…
        if df[col].isnull().sum() > 0:
            df[col] = df[col].fillna(df[col].mean())
            
        missing_after = df[col].isnull().sum()
        print(f"  âœ… {col}: {missing_before} â†’ {missing_after}")

# Ø«Ø§Ù†ÙŠØ§Ù‹: Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù†ØµÙŠØ©
categorical_columns = df.select_dtypes(include=['object']).columns
print(f"\nØ§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù†ØµÙŠØ©: {len(categorical_columns)} Ù…ØªØºÙŠØ±")

for col in categorical_columns:
    if df[col].isnull().sum() > 0:
        missing_before = df[col].isnull().sum()
        mode_value = df[col].mode()[0] if not df[col].mode().empty else 'Unknown'
        df[col] = df[col].fillna(mode_value)
        missing_after = df[col].isnull().sum()
        print(f"  âœ… {col}: {missing_before} â†’ {missing_after}")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
total_missing = df.isnull().sum().sum()
print(f"\nâœ… Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {total_missing}")

# Ø§Ù„Ø®Ø·ÙˆØ© 4: ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø±Ù‚Ù…ÙŠØ©
print("\n3ï¸âƒ£ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ø±Ù‚Ù…ÙŠØ©...")

df_processed = df.copy()
encoders = {}

# Label Encoding Ù„Ù…ØªØºÙŠØ± Status
if 'Status' in df_processed.columns:
    le_status = LabelEncoder()
    df_processed['Status'] = le_status.fit_transform(df_processed['Status'])
    encoders['Status'] = le_status
    print(f"  âœ… Status: {list(le_status.classes_)}")

# Target Encoding Ù„Ù„Ø¯ÙˆÙ„ (Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØªÙˆØ³Ø· Ù…ØªÙˆÙ‚Ø¹ Ø§Ù„Ø¹Ù…Ø±)
if 'Country' in df_processed.columns:
    country_means = df_processed.groupby('Country')[target_column].mean()
    df_processed['Country_encoded'] = df_processed['Country'].map(country_means)
    
    # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØªØ±Ù…ÙŠØ² Ø§Ù„Ø¯ÙˆÙ„
    country_encoding = country_means.to_dict()
    encoders['Country'] = country_encoding
    
    # Ø­Ø°Ù Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ
    df_processed = df_processed.drop('Country', axis=1)
    print(f"  âœ… Country: ØªÙ… ØªØ±Ù…ÙŠØ² {len(country_encoding)} Ø¯ÙˆÙ„Ø©")

# Ø§Ù„Ø®Ø·ÙˆØ© 5: ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
print("\n4ï¸âƒ£ ÙØ­Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©...")
print(f"Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {df_processed.shape[0]} ØµÙØŒ {df_processed.shape[1]} Ø¹Ù…ÙˆØ¯")
print(f"Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©: {df_processed.isnull().sum().sum()}")

# Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
if target_column in df_processed.columns:
    target_stats = df_processed[target_column].describe()
    print(f"\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª {target_column}:")
    print(f"Ø§Ù„Ù…ØªÙˆØ³Ø·: {target_stats['mean']:.2f}")
    print(f"Ø§Ù„ÙˆØ³ÙŠØ·: {target_stats['50%']:.2f}")
    print(f"Ø£Ù‚Ù„ Ù‚ÙŠÙ…Ø©: {target_stats['min']:.2f}")
    print(f"Ø£Ø¹Ù„Ù‰ Ù‚ÙŠÙ…Ø©: {target_stats['max']:.2f}")

# Ø§Ù„Ø®Ø·ÙˆØ© 6: Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
print("\n5ï¸âƒ£ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")

# Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
df_processed.to_csv('data_cleaned.csv', index=False)
print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ: data_cleaned.csv")

# Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª
import joblib
joblib.dump(encoders, 'encoders.joblib')
print("âœ… ØªÙ… Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ø­ÙˆÙ„Ø§Øª ÙÙŠ: encoders.joblib")

# Ø­ÙØ¸ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù
with open('target_column.txt', 'w', encoding='utf-8') as f:
    f.write(target_column)
print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù")

# Ø¹Ø±Ø¶ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
print(f"\nğŸ“‹ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
print(df_processed.head(3))

print(f"\nâœ… Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
print(f"ğŸ“ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©:")
print(f"   - data_cleaned.csv (Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©)")
print(f"   - encoders.joblib (Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ­ÙˆÙŠÙ„)")
print(f"   - target_column.txt (Ø§Ø³Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯Ù)")

print(f"\nğŸ¯ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©: ØªØ´ØºÙŠÙ„ model_development.py")
