import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import statsmodels.api as sm
import joblib
import warnings
warnings.filterwarnings('ignore')

# ุชุนููู ุงูุฎุท ููุฑุณูู ุงูุจูุงููุฉ
plt.rcParams['figure.figsize'] = (10, 6)
sns.set_style("whitegrid")

print("๐ค ุจุฏุก ุจูุงุก ูููุฐุฌ ุงูุชูุจุค ุจูุชููุน ุงูุนูุฑ...")

# ุงูุฎุทูุฉ 1: ุชุญููู ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ
df = pd.read_csv('data_cleaned.csv')
with open('target_column.txt', 'r', encoding='utf-8') as f:
    target_column = f.read().strip()

print(f"โ ุชู ุชุญููู ุงูุจูุงูุงุช: {df.shape}")
print(f"๐ฏ ุงูุนููุฏ ุงููุณุชูุฏู: '{target_column}'")

# ุงูุฎุทูุฉ 2: ุชุญููู ุงูุงุฑุชุจุงุท
print(f"\n1๏ธโฃ ุชุญููู ุงูุงุฑุชุจุงุท ูุน ูุชููุน ุงูุนูุฑ...")

# ุญุณุงุจ ุงูุงุฑุชุจุงุท ูุน ุงูุนููุฏ ุงููุณุชูุฏู
correlations = df.corr()[target_column].sort_values(key=abs, ascending=False)
print(f"\n๐ ุฃููู ุงูุงุฑุชุจุงุทุงุช ูุน {target_column}:")

for var, corr in correlations.items():
    if var != target_column:
        direction = "ููุฌุจ" if corr > 0 else "ุณุงูุจ"
        strength = "ููู" if abs(corr) > 0.7 else "ูุชูุณุท" if abs(corr) > 0.4 else "ุถุนูู"
        print(f"  {var}: {corr:.3f} ({direction} - {strength})")

# ุฑุณู ุฎุฑูุทุฉ ุงูุงุฑุชุจุงุท
plt.figure(figsize=(15, 12))
correlation_matrix = df.corr()
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))  # ุฅุฎูุงุก ุงููุตู ุงูุนููู
sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdBu_r', center=0, 
            fmt='.2f', square=True, cbar_kws={"shrink": .8})
plt.title('ุฎุฑูุทุฉ ุงูุงุฑุชุจุงุท ุจูู ุงููุชุบูุฑุงุช')
plt.tight_layout()
plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')
plt.show()

# ุงูุฎุทูุฉ 3: ุชุญุถูุฑ ุงูุจูุงูุงุช ููููุฐุฌุฉ
print(f"\n2๏ธโฃ ุชุญุถูุฑ ุงูุจูุงูุงุช ููููุฐุฌุฉ...")

X = df.drop(target_column, axis=1)
y = df[target_column]

print(f"ุนุฏุฏ ุงููุชุบูุฑุงุช ุงููุณุชููุฉ: {X.shape[1]}")
print(f"ุนุฏุฏ ุงูุนููุงุช: {X.shape[0]}")

# ุชูุณูู ุงูุจูุงูุงุช (80% ููุชุฏุฑูุจุ 20% ููุงุฎุชุจุงุฑ)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"ุจูุงูุงุช ุงูุชุฏุฑูุจ: {X_train.shape[0]} ุนููุฉ")
print(f"ุจูุงูุงุช ุงูุงุฎุชุจุงุฑ: {X_test.shape[0]} ุนููุฉ")

# ุงูุฎุทูุฉ 4: ุงููููุฐุฌ ุงูุฃุณุงุณู
print(f"\n3๏ธโฃ ุจูุงุก ุงููููุฐุฌ ุงูุฃุณุงุณู...")

baseline_model = LinearRegression()
baseline_model.fit(X_train, y_train)

y_pred_baseline = baseline_model.predict(X_test)

mae_baseline = mean_absolute_error(y_test, y_pred_baseline)
mse_baseline = mean_squared_error(y_test, y_pred_baseline)
rmse_baseline = np.sqrt(mse_baseline)
r2_baseline = r2_score(y_test, y_pred_baseline)

print(f"๐ ุฃุฏุงุก ุงููููุฐุฌ ุงูุฃุณุงุณู (ูุน ุฌููุน ุงููุชุบูุฑุงุช):")
print(f"  MAE: {mae_baseline:.3f} ุณูุฉ")
print(f"  RMSE: {rmse_baseline:.3f} ุณูุฉ") 
print(f"  Rยฒ: {r2_baseline:.3f} ({r2_baseline*100:.1f}%)")

# ุงูุฎุทูุฉ 5: Backward Elimination
print(f"\n4๏ธโฃ ุชุทุจูู Backward Elimination...")

def backward_elimination(X, y, significance_level=0.05):
    """ุชุทุจูู Backward Elimination ูุงุฎุชูุงุฑ ุฃูู ุงููุชุบูุฑุงุช"""
    X_with_const = sm.add_constant(X)
    features = X_with_const.columns.tolist()
    removed_features = []
    
    print("ุจุฏุก ุนูููุฉ ุงูุญุฐู ุงูุชุฏุฑูุฌู...")
    
    while True:
        model = sm.OLS(y, X_with_const[features]).fit()
        p_values = model.pvalues
        max_p_value = p_values.max()
        
        if max_p_value > significance_level:
            feature_with_max_p = p_values.idxmax()
            if feature_with_max_p != 'const':
                features.remove(feature_with_max_p)
                removed_features.append(feature_with_max_p)
                print(f"  โ ุญุฐู: {feature_with_max_p} (p-value: {max_p_value:.4f})")
        else:
            break
    
    if 'const' in features:
        features.remove('const')
    
    print(f"\nโ ุงูุชูุงุก ุงูุญุฐู ุงูุชุฏุฑูุฌู")
    print(f"ุงููุชุบูุฑุงุช ุงููุญุฐููุฉ ({len(removed_features)}): {removed_features}")
    print(f"ุงููุชุบูุฑุงุช ุงููุชุจููุฉ ({len(features)}): {features}")
    
    return features, model

selected_features, final_ols_model = backward_elimination(X_train, y_train)

# ุงูุฎุทูุฉ 6: ุงููููุฐุฌ ุงููุญุณู
print(f"\n5๏ธโฃ ุจูุงุก ุงููููุฐุฌ ุงููุญุณู...")

X_train_selected = X_train[selected_features]
X_test_selected = X_test[selected_features]

improved_model = LinearRegression()
improved_model.fit(X_train_selected, y_train)

y_pred_improved = improved_model.predict(X_test_selected)

mae_improved = mean_absolute_error(y_test, y_pred_improved)
mse_improved = mean_squared_error(y_test, y_pred_improved)
rmse_improved = np.sqrt(mse_improved)
r2_improved = r2_score(y_test, y_pred_improved)

print(f"๐ ุฃุฏุงุก ุงููููุฐุฌ ุงููุญุณู:")
print(f"  MAE: {mae_improved:.3f} ุณูุฉ")
print(f"  RMSE: {rmse_improved:.3f} ุณูุฉ")
print(f"  Rยฒ: {r2_improved:.3f} ({r2_improved*100:.1f}%)")

# ุงูุฎุทูุฉ 7: ููุงุฑูุฉ ุงูููุงุฐุฌ
print(f"\n6๏ธโฃ ููุงุฑูุฉ ุงูููุงุฐุฌ...")

comparison = pd.DataFrame({
    'ุงููููุงุณ': ['MAE (ุณูุฉ)', 'RMSE (ุณูุฉ)', 'Rยฒ (%)', 'ุนุฏุฏ ุงููุชุบูุฑุงุช'],
    'ุงููููุฐุฌ ุงูุฃุณุงุณู': [mae_baseline, rmse_baseline, r2_baseline*100, len(X.columns)],
    'ุงููููุฐุฌ ุงููุญุณู': [mae_improved, rmse_improved, r2_improved*100, len(selected_features)]
})

print(comparison.round(3))

# ุงุฎุชูุงุฑ ุงููููุฐุฌ ุงูุฃูุถู
if r2_improved >= r2_baseline - 0.01:  # ุฅุฐุง ูุงู ุงูุฃุฏุงุก ูุชูุงุฑุจุ ูุฎุชุงุฑ ุงูุฃุจุณุท
    final_model = improved_model
    final_features = selected_features
    final_r2 = r2_improved
    final_mae = mae_improved
    model_type = "ูุญุณู"
else:
    final_model = baseline_model
    final_features = list(X.columns)
    final_r2 = r2_baseline
    final_mae = mae_baseline
    model_type = "ุฃุณุงุณู"

print(f"\n๐ ุงููููุฐุฌ ุงููุฎุชุงุฑ: {model_type}")
print(f"ุฏูุฉ ุงููููุฐุฌ: {final_r2:.3f} ({final_r2*100:.1f}%)")
print(f"ูุชูุณุท ุงูุฎุทุฃ: {final_mae:.3f} ุณูุฉ")

# ุงูุฎุทูุฉ 8: ุญูุธ ุงููููุฐุฌ
print(f"\n7๏ธโฃ ุญูุธ ุงููููุฐุฌ ุงูููุงุฆู...")

joblib.dump(final_model, 'life_expectancy_model.joblib')
joblib.dump(final_features, 'selected_features.joblib')

print("โ ุชู ุญูุธ ุงููููุงุช:")
print("  - life_expectancy_model.joblib (ุงููููุฐุฌ)")
print("  - selected_features.joblib (ูุงุฆูุฉ ุงููุชุบูุฑุงุช)")

# ุงูุฎุทูุฉ 9: ุงุฎุชุจุงุฑ ุงููููุฐุฌ
print(f"\n8๏ธโฃ ุงุฎุชุจุงุฑ ุงููููุฐุฌ...")

# ุงุฎุชูุงุฑ ุนููุฉ ุนุดูุงุฆูุฉ ูู ุจูุงูุงุช ุงูุงุฎุชุจุงุฑ
sample_idx = np.random.choice(len(X_test), 3)
if model_type == "ูุญุณู":
    sample_pred = final_model.predict(X_test_selected.iloc[sample_idx])
else:
    sample_pred = final_model.predict(X_test.iloc[sample_idx])

print("๐งช ุงุฎุชุจุงุฑุงุช ุนุดูุงุฆูุฉ:")
for i, idx in enumerate(sample_idx):
    actual = y_test.iloc[idx]
    predicted = sample_pred[i]
    error = abs(actual - predicted)
    print(f"  ุงูุนููุฉ {i+1}: ูุนูู={actual:.1f}, ูุชููุน={predicted:.1f}, ุงูุฎุทุฃ={error:.1f}")

# ุงูุฎุทูุฉ 10: ุงูุฑุณูู ุงูุจูุงููุฉ
print(f"\n9๏ธโฃ ุฅูุดุงุก ุงูุฑุณูู ุงูุจูุงููุฉ...")

# ุฑุณู ููุงุฑูุฉ ุงูููุงุฐุฌ
fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))

# 1. ููุงุฑูุฉ ุงูููุงููุณ
metrics = ['MAE', 'RMSE', 'Rยฒ']
baseline_scores = [mae_baseline, rmse_baseline, r2_baseline]
improved_scores = [mae_improved, rmse_improved, r2_improved]

x_pos = np.arange(len(metrics))
width = 0.35

ax1.bar(x_pos - width/2, baseline_scores, width, label='ุฃุณุงุณู', alpha=0.7, color='lightblue')
ax1.bar(x_pos + width/2, improved_scores, width, label='ูุญุณู', alpha=0.7, color='lightgreen')
ax1.set_xlabel('ุงูููุงููุณ')
ax1.set_ylabel('ุงูููู')
ax1.set_title('ููุงุฑูุฉ ุฃุฏุงุก ุงูููุงุฐุฌ')
ax1.set_xticks(x_pos)
ax1.set_xticklabels(metrics)
ax1.legend()

# 2. ุงูููู ุงููุนููุฉ ููุงุจู ุงููุชููุนุฉ
if model_type == "ูุญุณู":
    y_pred_final = final_model.predict(X_test_selected)
else:
    y_pred_final = final_model.predict(X_test)

ax2.scatter(y_test, y_pred_final, alpha=0.6, color='blue')
ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
ax2.set_xlabel('ุงูููู ุงููุนููุฉ')
ax2.set_ylabel('ุงูููู ุงููุชููุนุฉ')
ax2.set_title(f'ุงููุนูู ููุงุจู ุงููุชููุน - ุงููููุฐุฌ {model_type}')

# 3. ุชูุฒูุน ุงูุฃุฎุทุงุก
residuals = y_test - y_pred_final
ax3.hist(residuals, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
ax3.set_xlabel('ุงูุฃุฎุทุงุก (ุงููุนูู - ุงููุชููุน)')
ax3.set_ylabel('ุงูุชูุฑุงุฑ')
ax3.set_title('ุชูุฒูุน ุฃุฎุทุงุก ุงููููุฐุฌ')
ax3.axvline(residuals.mean(), color='red', linestyle='--', 
           label=f'ุงููุชูุณุท: {residuals.mean():.2f}')
ax3.legend()

# 4. ุฃูููุฉ ุงููุชุบูุฑุงุช
feature_importance = pd.DataFrame({
    'ุงููุชุบูุฑ': final_features,
    'ุงููุนุงูู': final_model.coef_
})
feature_importance['ุงูุฃูููุฉ'] = abs(feature_importance['ุงููุนุงูู'])
feature_importance = feature_importance.sort_values('ุงูุฃูููุฉ', ascending=True).tail(10)

ax4.barh(range(len(feature_importance)), feature_importance['ุงูุฃูููุฉ'], 
         color='lightcoral', alpha=0.7)
ax4.set_yticks(range(len(feature_importance)))
ax4.set_yticklabels(feature_importance['ุงููุชุบูุฑ'])
ax4.set_xlabel('ุงูุฃูููุฉ (ุงููููุฉ ุงููุทููุฉ ูููุนุงูู)')
ax4.set_title('ุฃูู 10 ูุชุบูุฑุงุช ูู ุงููููุฐุฌ')

plt.tight_layout()
plt.savefig('model_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# ุงูุฎุทูุฉ 11: ุชูุฑูุฑ ููุงุฆู
print(f"\n๐ ุฅูุดุงุก ุงูุชูุฑูุฑ ุงูููุงุฆู...")

report = f"""
ุชูุฑูุฑ ูููุฐุฌ ุงูุชูุจุค ุจูุชููุน ุงูุนูุฑ
{"="*50}

๐ ูุนูููุงุช ุงูุจูุงูุงุช:
- ุฅุฌูุงูู ุงูุนููุงุช: {len(df):,}
- ุจูุงูุงุช ุงูุชุฏุฑูุจ: {len(X_train):,} ุนููุฉ
- ุจูุงูุงุช ุงูุงุฎุชุจุงุฑ: {len(X_test):,} ุนููุฉ
- ุงููุชุบูุฑุงุช ุงูุฃุตููุฉ: {len(X.columns)}
- ุงููุชุบูุฑุงุช ุงููุฎุชุงุฑุฉ: {len(final_features)}

๐ฏ ุงููููุฐุฌ ุงููุฎุชุงุฑ: {model_type}
- ุฏูุฉ ุงููููุฐุฌ (Rยฒ): {final_r2:.3f} ({final_r2*100:.1f}%)
- ูุชูุณุท ุงูุฎุทุฃ ุงููุทูู: {final_mae:.3f} ุณูุฉ
- ุงูุฌุฐุฑ ุงูุชุฑุจูุนู ููุชูุณุท ูุฑุจุน ุงูุฎุทุฃ: {rmse_improved if model_type == "ูุญุณู" else rmse_baseline:.3f} ุณูุฉ

๐ ุชูุณูุฑ ุงููุชุงุฆุฌ:
- ุงููููุฐุฌ ููุณุฑ {final_r2*100:.1f}% ูู ุงูุชุจุงูู ูู ูุชููุน ุงูุนูุฑ
- ูุชูุณุท ุฎุทุฃ ุงูุชูุจุค: ยฑ{final_mae:.1f} ุณูุฉ
- ุงููููุฐุฌ {"ููุชุงุฒ" if final_r2 > 0.9 else "ุฌูุฏ ุฌุฏุงู" if final_r2 > 0.8 else "ุฌูุฏ" if final_r2 > 0.7 else "ููุจูู"}

๐ ุฃูู ุงููุชุบูุฑุงุช ุงููุคุซุฑุฉ:
"""

# ุฅุถุงูุฉ ุฃูู ุงููุชุบูุฑุงุช
importance_df = pd.DataFrame({
    'ุงููุชุบูุฑ': final_features,
    'ุงููุนุงูู': final_model.coef_
}).sort_values(key=lambda x: abs(x), by='ุงููุนุงูู', ascending=False).head(5)

for _, row in importance_df.iterrows():
    effect = "ูุฒูุฏ" if row['ุงููุนุงูู'] > 0 else "ูููู"
    report += f"- {row['ุงููุชุบูุฑ']}: {effect} ูุชููุน ุงูุนูุฑ ุจู {abs(row['ุงููุนุงูู']):.3f} ุณูุฉ\n"

report += f"""
๐พ ุงููููุงุช ุงููุญููุธุฉ:
- life_expectancy_model.joblib: ุงููููุฐุฌ ุงูููุงุฆู
- selected_features.joblib: ูุงุฆูุฉ ุงููุชุบูุฑุงุช ุงููุฎุชุงุฑุฉ
- encoders.joblib: ูุนูููุงุช ุชุญููู ุงูุจูุงูุงุช
- data_cleaned.csv: ุงูุจูุงูุงุช ุงููุนุงูุฌุฉ
- correlation_heatmap.png: ุฎุฑูุทุฉ ุงูุงุฑุชุจุงุท
- model_analysis.png: ุชุญููู ุงููููุฐุฌ

๐ ุฌุงูุฒ ูุจูุงุก API!
"""

with open('model_report.txt', 'w', encoding='utf-8') as f:
    f.write(report)

print("โ ุชู ุญูุธ ุงูุชูุฑูุฑ ูู: model_report.txt")

print(f"\n๐ ุชู ุงูุงูุชูุงุก ูู ุจูุงุก ุงููููุฐุฌ ุจูุฌุงุญ!")
print(f"๐ฏ ุงูุฎุทูุฉ ุงูุชุงููุฉ: ุจูุงุก API ูููููุฐุฌ")
print(f"๐ ุฏูุฉ ุงููููุฐุฌ: {final_r2*100:.1f}%")
print(f"๐ ุฌููุน ุงููููุงุช ูุญููุธุฉ ููุฌูุฒุฉ ูุจูุงุก API")